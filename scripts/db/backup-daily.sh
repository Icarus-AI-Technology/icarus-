#!/bin/bash
# ============================================
# Script: Backup AutomÃ¡tico DiÃ¡rio
# VersÃ£o: 1.0
# DescriÃ§Ã£o: Backup completo do Postgres com retenÃ§Ã£o
# Uso: Executar via cron diariamente
# ============================================

set -e  # Exit on error
set -o pipefail  # Exit on pipe failure

# ============================================
# CONFIGURAÃ‡ÃƒO
# ============================================

# DiretÃ³rio de backups (ajustar conforme necessÃ¡rio)
BACKUP_DIR="${BACKUP_DIR:-/Users/daxmeneghel/icarus-make/backups}"
LOG_FILE="${BACKUP_DIR}/backup.log"

# RetenÃ§Ã£o (dias)
RETENTION_DAYS=30

# Prefixo dos arquivos
PREFIX="icarus_backup"

# Timestamp
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
DATE_ONLY=$(date +%Y%m%d)

# Nome do arquivo de backup
BACKUP_FILE="${BACKUP_DIR}/${PREFIX}_${TIMESTAMP}.sql.gz"

# ============================================
# FUNÃ‡Ã•ES
# ============================================

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

error_exit() {
    log "âŒ ERRO: $1"
    exit 1
}

# ============================================
# VALIDAÃ‡Ã•ES
# ============================================

# Verificar se SUPABASE_DB_URL estÃ¡ configurado
if [ -z "$SUPABASE_DB_URL" ]; then
    error_exit "VariÃ¡vel SUPABASE_DB_URL nÃ£o configurada"
fi

# Criar diretÃ³rio de backups se nÃ£o existir
mkdir -p "$BACKUP_DIR" || error_exit "Falha ao criar diretÃ³rio $BACKUP_DIR"

# Verificar se pg_dump estÃ¡ disponÃ­vel
if ! command -v pg_dump &> /dev/null; then
    error_exit "pg_dump nÃ£o encontrado. Instale PostgreSQL client tools"
fi

# Verificar se gzip estÃ¡ disponÃ­vel
if ! command -v gzip &> /dev/null; then
    error_exit "gzip nÃ£o encontrado"
fi

# ============================================
# BACKUP
# ============================================

log "ğŸš€ Iniciando backup automÃ¡tico..."
log "ğŸ“ Destino: $BACKUP_FILE"

# Testar conexÃ£o
log "ğŸ”Œ Testando conexÃ£o..."
if ! psql "$SUPABASE_DB_URL" -c "SELECT 1;" > /dev/null 2>&1; then
    error_exit "Falha na conexÃ£o com o banco de dados"
fi

log "âœ… ConexÃ£o OK"

# Executar backup com compressÃ£o
log "ğŸ’¾ Executando pg_dump..."

START_TIME=$(date +%s)

pg_dump "$SUPABASE_DB_URL" \
    --format=plain \
    --no-owner \
    --no-acl \
    --clean \
    --if-exists \
    --verbose \
    2>> "$LOG_FILE" \
    | gzip > "$BACKUP_FILE"

END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

if [ $? -eq 0 ]; then
    BACKUP_SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
    log "âœ… Backup concluÃ­do com sucesso!"
    log "ğŸ“Š Tamanho: $BACKUP_SIZE"
    log "â±ï¸  DuraÃ§Ã£o: ${DURATION}s"
else
    error_exit "Falha ao executar pg_dump"
fi

# ============================================
# VERIFICAÃ‡ÃƒO DE INTEGRIDADE
# ============================================

log "ğŸ” Verificando integridade..."

# Verificar se arquivo existe e nÃ£o estÃ¡ vazio
if [ ! -s "$BACKUP_FILE" ]; then
    error_exit "Arquivo de backup vazio ou nÃ£o existe"
fi

# Testar descompressÃ£o
if ! gunzip -t "$BACKUP_FILE" 2>> "$LOG_FILE"; then
    error_exit "Arquivo de backup corrompido (falha no gzip test)"
fi

log "âœ… Integridade verificada"

# ============================================
# BACKUP INCREMENTAL (apenas schema se jÃ¡ existe backup hoje)
# ============================================

SCHEMA_FILE="${BACKUP_DIR}/${PREFIX}_schema_${DATE_ONLY}.sql"

if [ ! -f "$SCHEMA_FILE" ]; then
    log "ğŸ“ Salvando schema..."
    
    pg_dump "$SUPABASE_DB_URL" \
        --schema-only \
        --no-owner \
        --no-acl \
        2>> "$LOG_FILE" \
        > "$SCHEMA_FILE"
    
    if [ $? -eq 0 ]; then
        log "âœ… Schema salvo: $SCHEMA_FILE"
    else
        log "âš ï¸  Falha ao salvar schema (nÃ£o-crÃ­tico)"
    fi
fi

# ============================================
# LIMPEZA (RETENÃ‡ÃƒO)
# ============================================

log "ğŸ§¹ Aplicando polÃ­tica de retenÃ§Ã£o ($RETENTION_DAYS dias)..."

# Remover backups completos antigos
DELETED_COUNT=0
find "$BACKUP_DIR" -name "${PREFIX}_*.sql.gz" -type f -mtime +$RETENTION_DAYS -print0 | while IFS= read -r -d '' file; do
    log "ğŸ—‘ï¸  Removendo: $(basename "$file")"
    rm -f "$file"
    DELETED_COUNT=$((DELETED_COUNT + 1))
done

# Manter apenas schemas dos Ãºltimos 7 dias
find "$BACKUP_DIR" -name "${PREFIX}_schema_*.sql" -type f -mtime +7 -delete

if [ $DELETED_COUNT -eq 0 ]; then
    log "âœ… Nenhum backup expirado encontrado"
else
    log "âœ… $DELETED_COUNT backup(s) antigo(s) removido(s)"
fi

# ============================================
# ESTATÃSTICAS
# ============================================

TOTAL_BACKUPS=$(find "$BACKUP_DIR" -name "${PREFIX}_*.sql.gz" -type f | wc -l)
TOTAL_SIZE=$(du -sh "$BACKUP_DIR" | cut -f1)

log "ğŸ“Š EstatÃ­sticas:"
log "   - Total de backups: $TOTAL_BACKUPS"
log "   - EspaÃ§o total: $TOTAL_SIZE"
log "   - Ãšltimo backup: $BACKUP_FILE"

# ============================================
# UPLOAD PARA CLOUD (OPCIONAL)
# ============================================

# Descomentar se quiser fazer upload para S3/Google Cloud
# if command -v aws &> /dev/null; then
#     log "â˜ï¸  Fazendo upload para S3..."
#     aws s3 cp "$BACKUP_FILE" "s3://seu-bucket/backups/" --storage-class STANDARD_IA
#     if [ $? -eq 0 ]; then
#         log "âœ… Upload para S3 concluÃ­do"
#     else
#         log "âš ï¸  Falha no upload para S3 (nÃ£o-crÃ­tico)"
#     fi
# fi

# ============================================
# NOTIFICAÃ‡ÃƒO (OPCIONAL)
# ============================================

# Descomentar para enviar notificaÃ§Ã£o por e-mail
# if [ $? -eq 0 ]; then
#     echo "Backup ICARUS concluÃ­do com sucesso em $(date)" | mail -s "âœ… Backup OK - ICARUS" admin@empresa.com
# fi

# ============================================
# FINALIZAÃ‡ÃƒO
# ============================================

log "ğŸ‰ Processo de backup concluÃ­do!"
log "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

exit 0

